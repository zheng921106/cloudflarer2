name: R2 最终校验（按 GLOB 分片，校验哈希）

on:
  workflow_dispatch: {}
  # schedule:
  #   - cron: "30 3 * * *"   # 可选：每日 03:30 收尾校验（UTC）

env:
  SRC_BUCKET: yasyadong001
  DST_BUCKET: yas003

  TRANSFERS: "4"
  CHECKERS: "16"
  UPLOAD_CONC: "4"
  BW_LIMIT: "0"
  TPS_LIMIT: "12"
  CHUNK_SIZE: "32M"
  COPY_CUTOFF: "256M"
  MAX_RETRIES: "8"
  LOW_LEVEL_RETRIES: "20"

jobs:
  verify:
    name: 最终一致性校验
    runs-on: ubuntu-latest
    timeout-minutes: 360
    strategy:
      fail-fast: false
      matrix:
        shard:
          - "0/**"
          - "1/**"
          - "2/**"
          - "3/**"
          - "4/**"
          - "5/**"
          - "6/**"
          - "7/**"
          - "8/**"
          - "9/**"
          - "a/**"
          - "b/**"
          - "c/**"
          - "d/**"
          - "e/**"
          - "f/**"

    steps:
      - name: 检出代码
        uses: actions/checkout@v4

      - name: 安装 rclone
        run: |
          curl -fsSL https://rclone.org/install.sh | sudo bash
          rclone version

      - name: 配置 R2 源和目标
        env:
          R2PUSH_ACCESS_KEY:  ${{ secrets.R2PUSH_ACCESS_KEY }}
          R2PUSH_SECRET_KEY:  ${{ secrets.R2PUSH_SECRET_KEY }}
          R2PUSH_ENDPOINT:    ${{ secrets.R2PUSH_ENDPOINT }}
          R2DST_ACCESS_KEY:   ${{ secrets.R2DST_ACCESS_KEY }}
          R2DST_SECRET_KEY:   ${{ secrets.R2DST_SECRET_KEY }}
          R2DST_ENDPOINT:     ${{ secrets.R2DST_ENDPOINT }}
        run: |
          set -euo pipefail
          rclone config create r2push s3 \
            provider=Other env_auth=false \
            access_key_id="${R2PUSH_ACCESS_KEY}" secret_access_key="${R2PUSH_SECRET_KEY}" \
            region=auto endpoint="${R2PUSH_ENDPOINT}" \
            s3-chunk-size="${CHUNK_SIZE}" s3-upload-concurrency="${UPLOAD_CONC}"

          rclone config create r2dst s3 \
            provider=Other env_auth=false \
            access_key_id="${R2DST_ACCESS_KEY}" secret_access_key="${R2DST_SECRET_KEY}" \
            region=auto endpoint="${R2DST_ENDPOINT}" \
            s3-chunk-size="${CHUNK_SIZE}" s3-upload-concurrency="${UPLOAD_CONC}"

          rclone listremotes

      - name: 修复复制（按分片，带哈希比对）
        run: |
          set -euo pipefail
          mkdir -p logs
          SAFE_TAG="$(printf '%s' '${{ matrix.shard }}' | tr '/' '_')"
          LOG_FILE="logs/r2_repair_${SAFE_TAG}_$(date -u +%F_%H-%M-%S).log"

          echo "[$(date -u '+%F %T')] 修复复制（带 --checksum），范围: ${{ matrix.shard }}" | tee -a "$LOG_FILE"

          rclone copy "r2push:${SRC_BUCKET}" "r2dst:${DST_BUCKET}" \
            --fast-list --metadata --checksum \
            --include "${{ matrix.shard }}" --exclude="**" \
            --transfers "${TRANSFERS}" --checkers "${CHECKERS}" \
            --bwlimit "${BW_LIMIT}" --tpslimit "${TPS_LIMIT}" \
            --s3-chunk-size "${CHUNK_SIZE}" --s3-copy-cutoff "${COPY_CUTOFF}" \
            --retries "${MAX_RETRIES}" --low-level-retries "${LOW_LEVEL_RETRIES}" \
            --progress 2>&1 | tee -a "$LOG_FILE"

      - name: 严格校验（必须通过）
        run: |
          set -euo pipefail
          mkdir -p logs
          SAFE_TAG="$(printf '%s' '${{ matrix.shard }}' | tr '/' '_')"
          LOG_FILE="logs/r2_verify_${SAFE_TAG}_$(date -u +%F_%H-%M-%S).log"

          echo "[$(date -u '+%F %T')] 最终严格校验（带 --checksum），范围: ${{ matrix.shard }}" | tee -a "$LOG_FILE"

          rclone check "r2push:${SRC_BUCKET}" "r2dst:${DST_BUCKET}" \
            --one-way --checksum --checkers "${CHECKERS}" \
            --include "${{ matrix.shard }}" --exclude="**" \
            --progress 2>&1 | tee -a "$LOG_FILE"

      - name: 上传日志
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: 最终校验日志-${{ matrix.shard }}
          path: logs/
          retention-days: 14
