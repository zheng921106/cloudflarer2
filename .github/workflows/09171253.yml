name: R2 全量迁移（32位十六进制目录，不校验，含诊断）

on:
  workflow_dispatch: {}

env:
  SRC_BUCKET: yasyadong001
  DST_BUCKET: yas004
  ROOT_PREFIX: ""   # 若目录不在桶根，填上级前缀；否则留空

  TRANSFERS: "6"
  CHECKERS: "16"
  UPLOAD_CONC: "4"
  BW_LIMIT: "0"
  TPS_LIMIT: "16"
  CHUNK_SIZE: "32M"
  COPY_CUTOFF: "256M"
  MAX_RETRIES: "8"
  LOW_LEVEL_RETRIES: "20"

jobs:
  migrate:
    runs-on: ubuntu-latest
    timeout-minutes: 360
    strategy:
      fail-fast: false
      matrix:
        shard: [ "0","1","2","3","4","5","6","7","8","9","A","B","C","D","E","F" ]

    steps:
      - name: 安装 rclone
        run: |
          set -euo pipefail
          curl -fsSL https://rclone.org/install.sh | sudo bash
          rclone version

      - name: 配置 R2 源与目标
        env:
          R2PUSH_ACCESS_KEY:  ${{ secrets.R2PUSH_ACCESS_KEY }}
          R2PUSH_SECRET_KEY:  ${{ secrets.R2PUSH_SECRET_KEY }}
          R2PUSH_ENDPOINT:    ${{ secrets.R2PUSH_ENDPOINT }}
          R2DST_ACCESS_KEY:   ${{ secrets.R2DST_ACCESS_KEY }}
          R2DST_SECRET_KEY:   ${{ secrets.R2DST_SECRET_KEY }}
          R2DST_ENDPOINT:     ${{ secrets.R2DST_ENDPOINT }}
        run: |
          set -euo pipefail
          # 基础校验：Secrets 不能为空
          for v in R2PUSH_ACCESS_KEY R2PUSH_SECRET_KEY R2PUSH_ENDPOINT R2DST_ACCESS_KEY R2DST_SECRET_KEY R2DST_ENDPOINT; do
            if [ -z "${!v:-}" ]; then
              echo "❌ 缺少 Secret：$v" >&2; exit 1
            fi
          done

          rclone config create r2src s3 \
            provider=Other env_auth=false \
            access_key_id="${R2PUSH_ACCESS_KEY}" secret_access_key="${R2PUSH_SECRET_KEY}" \
            region=auto endpoint="${R2PUSH_ENDPOINT}" \
            s3-force-path-style=true no_check_bucket=true \
            s3-chunk-size="${CHUNK_SIZE}" s3-upload-concurrency="${UPLOAD_CONC}"

          rclone config create r2dst s3 \
            provider=Other env_auth=false \
            access_key_id="${R2DST_ACCESS_KEY}" secret_access_key="${R2DST_SECRET_KEY}" \
            region=auto endpoint="${R2DST_ENDPOINT}" \
            s3-force-path-style=true no_check_bucket=true \
            s3-chunk-size="${CHUNK_SIZE}" s3-upload-concurrency="${UPLOAD_CONC}"

          rclone listremotes

      - name: 准备日志目录
        run: |
          set -euo pipefail
          mkdir -p logs filters

      - name: 源桶连通性自检（显示错误细节）
        run: |
          set -euo pipefail
          BASE="r2src:${SRC_BUCKET}"
          if [ -n "${ROOT_PREFIX}" ]; then
            BASE="${BASE}/${ROOT_PREFIX%/}"
          fi
          echo "== 试列举 ${BASE} 顶层前 10 项 =="
          if ! rclone lsf "${BASE}" --max-depth 1 --max 10 -vv --retries 1 2>logs/selfcheck.err; then
            echo "❌ 无法列举源桶，末尾错误如下："
            tail -n 50 logs/selfcheck.err
            exit 1
          fi

      - name: 确保目标桶存在
        run: |
          set -euo pipefail
          if ! rclone lsd "r2dst:" | grep -qE "\s${DST_BUCKET}\s*$"; then
            echo "创建目标桶：${DST_BUCKET}"
            rclone mkdir "r2dst:${DST_BUCKET}"
          else
            echo "目标桶已存在：${DST_BUCKET}"
          fi

      - name: 生成分片过滤（32位十六进制目录，支持大小写）
        id: buildfilter
        run: |
          set -euo pipefail
          FILTER="filters/${{ matrix.shard }}.filter"
          : > "$FILTER"

          BASE="r2src:${SRC_BUCKET}"
          if [ -n "${ROOT_PREFIX}" ]; then
            BASE="${BASE}/${ROOT_PREFIX%/}"
          fi

          UP="${{ matrix.shard }}"
          LOW="$(printf '%s' "${{ matrix.shard }}" | tr 'A-Z' 'a-z')"

          : > shard_dirs.txt
          rclone lsf "${BASE}/${UP}"  --dirs-only --max-depth 1 >> shard_dirs.txt || true
          if [ "${LOW}" != "${UP}" ]; then
            rclone lsf "${BASE}/${LOW}" --dirs-only --max-depth 1 >> shard_dirs.txt || true
          fi

          awk 'BEGIN{IGNORECASE=1} /^[0-9A-F]{32}\/$/ {print}' shard_dirs.txt | sort -u > matched_dirs.txt
          cnt=$(wc -l < matched_dirs.txt | tr -d " ")
          echo "分片 '${{ matrix.shard }}' 命中目录数：$cnt"
          head -50 matched_dirs.txt || true

          if [ "$cnt" -gt 0 ]; then
            if [ -n "${ROOT_PREFIX}" ]; then
              while IFS= read -r d; do printf "+ %s/%s**\n" "${ROOT_PREFIX%/}" "$d"; done < matched_dirs.txt > "$FILTER"
            else
              while IFS= read -r d; do printf "+ %s**\n" "$d"; done < matched_dirs.txt > "$FILTER"
            fi
            echo "- **" >> "$FILTER"
            echo "file=$FILTER" >> "$GITHUB_OUTPUT"
            echo "empty=false" >> "$GITHUB_OUTPUT"
          else
            echo "# empty shard" > "$FILTER"
            echo "logs/skip_${{ matrix.shard }}.log" > "logs/skip_${{ matrix.shard }}.log"
            echo "file=$FILTER" >> "$GITHUB_OUTPUT"
            echo "empty=true" >> "$GITHUB_OUTPUT"
          fi

      - name: 执行迁移（不校验）
        if: steps.buildfilter.outputs.empty == 'false'
        run: |
          set -euo pipefail
          LOG="logs/migrate_${{ matrix.shard }}_$(date -u +%F_%H-%M-%S).log"
          rclone copy "r2src:${SRC_BUCKET}" "r2dst:${DST_BUCKET}" \
            --fast-list --metadata \
            --filter-from "${{ steps.buildfilter.outputs.file }}" \
            --transfers "${TRANSFERS}" --checkers "${CHECKERS}" \
            --bwlimit "${BW_LIMIT}" --tpslimit "${TPS_LIMIT}" \
            --s3-chunk-size "${CHUNK_SIZE}" --s3-copy-cutoff "${COPY_CUTOFF}" \
            --retries "${MAX_RETRIES}" --low-level-retries "${LOW_LEVEL_RETRIES}" \
            --progress 2>&1 | tee -a "$LOG"

      - name: 上传日志
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: 迁移日志-${{ matrix.shard }}
          path: logs/
          if-no-files-found: ignore
          retention-days: 7
