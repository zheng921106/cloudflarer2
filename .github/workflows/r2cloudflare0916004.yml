name: R2 Final Verify (glob-sharded, checksum)

on:
  workflow_dispatch: {}
  # schedule:
  #   - cron: "30 3 * * *"   # 可选：每日 03:30 收尾校验（UTC）

env:
  SRC_BUCKET: yasyadong001
  DST_BUCKET: yas004

  TRANSFERS: "4"
  CHECKERS: "16"
  UPLOAD_CONC: "4"
  BW_LIMIT: "0"
  TPS_LIMIT: "12"
  CHUNK_SIZE: "32M"
  COPY_CUTOFF: "256M"
  MAX_RETRIES: "8"
  LOW_LEVEL_RETRIES: "20"

jobs:
  verify:
    runs-on: ubuntu-latest
    timeout-minutes: 360
    strategy:
      fail-fast: false
      matrix:
        shard:
          - "0/**"
          - "1/**"
          - "2/**"
          - "3/**"
          - "4/**"
          - "5/**"
          - "6/**"
          - "7/**"
          - "8/**"
          - "9/**"
          - "a/**"
          - "b/**"
          - "c/**"
          - "d/**"
          - "e/**"
          - "f/**"

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Install rclone
        run: |
          curl -fsSL https://rclone.org/install.sh | sudo bash
          rclone version

      - name: Configure rclone remotes (Cloudflare R2 → R2)
        env:
          R2PUSH_ACCESS_KEY:  ${{ secrets.R2PUSH_ACCESS_KEY }}
          R2PUSH_SECRET_KEY:  ${{ secrets.R2PUSH_SECRET_KEY }}
          R2PUSH_ENDPOINT:    ${{ secrets.R2PUSH_ENDPOINT }}
          R2DST_ACCESS_KEY:   ${{ secrets.R2DST_ACCESS_KEY }}
          R2DST_SECRET_KEY:   ${{ secrets.R2DST_SECRET_KEY }}
          R2DST_ENDPOINT:     ${{ secrets.R2DST_ENDPOINT }}
        run: |
          set -euo pipefail
          rclone config create r2push s3 \
            provider=Other env_auth=false \
            access_key_id="${R2PUSH_ACCESS_KEY}" secret_access_key="${R2PUSH_SECRET_KEY}" \
            region=auto endpoint="${R2PUSH_ENDPOINT}" \
            s3-chunk-size="${CHUNK_SIZE}" s3-upload-concurrency="${UPLOAD_CONC}"

          rclone config create r2dst s3 \
            provider=Other env_auth=false \
            access_key_id="${R2DST_ACCESS_KEY}" secret_access_key="${R2DST_SECRET_KEY}" \
            region=auto endpoint="${R2DST_ENDPOINT}" \
            s3-chunk-size="${CHUNK_SIZE}" s3-upload-concurrency="${UPLOAD_CONC}"

          rclone listremotes

      # 生成“安全分片名”，用于日志文件名和 artifact 名
      - name: Sanitize shard name
        id: safetag
        run: |
          set -euo pipefail
          SAFE_TAG="$(printf '%s' '${{ matrix.shard }}' | tr -c 'A-Za-z0-9._-' '_' )"
          echo "safe=${SAFE_TAG}" >> "$GITHUB_OUTPUT"

      - name: Repair copy (checksum, glob shard)
        run: |
          set -euo pipefail
          mkdir -p logs
          LOG_FILE="logs/r2_repair_${{ steps.safetag.outputs.safe }}_$(date -u +%F_%H-%M-%S).log"

          echo "[$(date -u '+%F %T')] Repair copy with checksum, include: ${{ matrix.shard }}" | tee -a "$LOG_FILE"

          rclone copy "r2push:${SRC_BUCKET}" "r2dst:${DST_BUCKET}" \
            --fast-list --metadata --checksum \
            --include "${{ matrix.shard }}" --exclude="**" \
            --transfers "${TRANSFERS}" --checkers "${CHECKERS}" \
            --bwlimit "${BW_LIMIT}" --tpslimit "${TPS_LIMIT}" \
            --s3-chunk-size "${CHUNK_SIZE}" --s3-copy-cutoff "${COPY_CUTOFF}" \
            --retries "${MAX_RETRIES}" --low-level-retries "${LOW_LEVEL_RETRIES}" \
            --progress 2>&1 | tee -a "$LOG_FILE"

      - name: Strict verify (checksum, must pass)
        run: |
          set -euo pipefail
          mkdir -p logs
          LOG_FILE="logs/r2_verify_${{ steps.safetag.outputs.safe }}_$(date -u +%F_%H-%M-%S).log"

          echo "[$(date -u '+%F %T')] Final verify with checksum, include: ${{ matrix.shard }}" | tee -a "$LOG_FILE"

          rclone check "r2push:${SRC_BUCKET}" "r2dst:${DST_BUCKET}" \
            --one-way --checksum --checkers "${CHECKERS}" \
            --include "${{ matrix.shard }}" --exclude="**" \
            --progress 2>&1 | tee -a "$LOG_FILE"

      - name: Upload logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: r2-final-verify-logs-${{ steps.safetag.outputs.safe }}
          path: logs/
          retention-days: 14
