name: R2 Migrate HexDirs (no check)

on:
  workflow_dispatch: {}
  # 如需定时续跑，按需开启（UTC 时间）
  # schedule:
  #   - cron: "0 * * * *"

env:
  SRC_BUCKET: yasyadong001
  DST_BUCKET: yas004

  # 吞吐参数（小文件友好，先稳后快）
  TRANSFERS: "6"
  CHECKERS: "16"
  UPLOAD_CONC: "4"
  BW_LIMIT: "0"          # 不限速；如需限速改成 "10M"
  TPS_LIMIT: "16"        # 如遇 429 可下调
  CHUNK_SIZE: "32M"
  COPY_CUTOFF: "256M"
  MAX_RETRIES: "8"
  LOW_LEVEL_RETRIES: "20"
  # 如担心在写入中的半成品，可加 MIN_AGE（例：60s），默认不启用
  # MIN_AGE: "60s"

jobs:
  migrate:
    runs-on: ubuntu-latest
    timeout-minutes: 360
    strategy:
      fail-fast: false
      matrix:
        shard: [ "0","1","2","3","4","5","6","7","8","9","A","B","C","D","E","F" ]

    steps:
      - name: 检出
        uses: actions/checkout@v4

      - name: 安装 rclone
        run: |
          curl -fsSL https://rclone.org/install.sh | sudo bash
          rclone version

      - name: 配置 R2 源与目标
        env:
          R2PUSH_ACCESS_KEY:  ${{ secrets.R2PUSH_ACCESS_KEY }}
          R2PUSH_SECRET_KEY:  ${{ secrets.R2PUSH_SECRET_KEY }}
          R2PUSH_ENDPOINT:    ${{ secrets.R2PUSH_ENDPOINT }}
          R2DST_ACCESS_KEY:   ${{ secrets.R2DST_ACCESS_KEY }}
          R2DST_SECRET_KEY:   ${{ secrets.R2DST_SECRET_KEY }}
          R2DST_ENDPOINT:     ${{ secrets.R2DST_ENDPOINT }}
        run: |
          set -euo pipefail
          rclone config create r2push s3 \
            provider=Other env_auth=false \
            access_key_id="${R2PUSH_ACCESS_KEY}" secret_access_key="${R2PUSH_SECRET_KEY}" \
            region=auto endpoint="${R2PUSH_ENDPOINT}" \
            s3-chunk-size="${CHUNK_SIZE}" s3-upload-concurrency="${UPLOAD_CONC}"
          rclone config create r2dst s3 \
            provider=Other env_auth=false \
            access_key_id="${R2DST_ACCESS_KEY}" secret_access_key="${R2DST_SECRET_KEY}" \
            region=auto endpoint="${R2DST_ENDPOINT}" \
            s3-chunk-size="${CHUNK_SIZE}" s3-upload-concurrency="${UPLOAD_CONC}"
          rclone listremotes

      - name: 确保目标桶存在
        run: |
          set -euo pipefail
          if ! rclone lsd "r2dst:" | grep -qE "\s${DST_BUCKET}\s*$"; then
            echo "创建目标桶：${DST_BUCKET}"
            rclone mkdir "r2dst:${DST_BUCKET}"
          else
            echo "目标桶已存在：${DST_BUCKET}"
          fi

      - name: 生成分片过滤规则（仅 32 位十六进制目录）
        id: buildfilter
        run: |
          set -euo pipefail
          mkdir -p filters
          FILTER="filters/${{ matrix.shard }}.filter"
          : > "$FILTER"

          # 列出顶层“目录”（伪目录），仅第一层
          rclone lsf "r2push:${SRC_BUCKET}" --dirs-only --max-depth 1 > all_dirs.txt

          # 选出：目录名为 32 位十六进制，且首字符属于当前分片（不区分大小写）
          awk -v sh="${{ matrix.shard }}" '
            BEGIN{ IGNORECASE=1 }
            /^[0-9A-F]{32}\/$/ {
              dir=$0
              first=substr(dir,1,1)
              if (tolower(first)==tolower(sh)) print dir
            }
          ' all_dirs.txt > matched_dirs.txt

          echo "本分片匹配目录："
          cat matched_dirs.txt || true

          if [ -s matched_dirs.txt ]; then
            while IFS= read -r d; do
              printf "+ %s**\n" "$d"
            done < matched_dirs.txt > "$FILTER"
            echo "- **" >> "$FILTER"
            echo "file=$FILTER" >> "$GITHUB_OUTPUT"
            echo "empty=false" >> "$GITHUB_OUTPUT"
          else
            echo "# empty shard" > "$FILTER"
            echo "file=$FILTER" >> "$GITHUB_OUTPUT"
            echo "empty=true" >> "$GITHUB_OUTPUT"
          fi

      - name: 执行迁移（无校验，仅复制）
        if: steps.buildfilter.outputs.empty == 'false'
        run: |
          set -euo pipefail
          mkdir -p logs
          LOG_FILE="logs/r2_copy_${{ matrix.shard }}_$(date -u +%F_%H-%M-%S).log"

          echo "开始迁移，分片=${{ matrix.shard }}  规则=${{ steps.buildfilter.outputs.file }}" | tee -a "$LOG_FILE"

          rclone copy "r2push:${SRC_BUCKET}" "r2dst:${DST_BUCKET}" \
            --fast-list --metadata \
            --filter-from "${{ steps.buildfilter.outputs.file }}" \
            --transfers "${TRANSFERS}" --checkers "${CHECKERS}" \
            --bwlimit "${BW_LIMIT}" --tpslimit "${TPS_LIMIT}" \
            --s3-chunk-size "${CHUNK_SIZE}" --s3-copy-cutoff "${COPY_CUTOFF}" \
            --retries "${MAX_RETRIES}" --low-level-retries "${LOW_LEVEL_RETRIES}" \
            --progress 2>&1 | tee -a "$LOG_FILE"
            # 如需避免搬运“正在写入”的文件，取消注释下一行：
            # --min-age "${MIN_AGE}"

      - name: 上传日志
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: r2-migrate-hex-${{ matrix.shard }}
          path: logs/
          retention-days: 7
