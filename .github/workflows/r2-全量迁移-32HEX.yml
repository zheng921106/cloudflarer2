name: Cloudflare R2 Bucket Migration (rclone) - Optimized Version

on:
  workflow_dispatch:
    inputs:
      SRC_BUCKET:
        description: "A桶名称（来源桶名）"
        required: true
        type: string
        default: "yasyadong001"
      DST_BUCKET:
        description: "B桶名称（目标桶名）"
        required: true
        type: string
        default: "yas009"
      MODE:
        description: "迁移模式"
        required: true
        default: "copy"
        type: choice
        options: ["copy", "sync"]
      TRANSFERS:
        description: "并发传输数"
        required: true
        default: "64"
        type: string
      CHECKERS:
        description: "并发校验数"
        required: true
        default: "128"
        type: string
      CHUNK_SIZE:
        description: "分块大小"
        required: true
        default: "256M"
        type: string

jobs:
  migrate:
    name: Optimized R2 Migration
    runs-on: ubuntu-latest
    timeout-minutes: 10080  # 7天超时
    env:
      SRC_BUCKET: ${{ inputs.SRC_BUCKET }}
      DST_BUCKET: ${{ inputs.DST_BUCKET }}
      MODE: ${{ inputs.MODE }}
      TRANSFERS: ${{ inputs.TRANSFERS }}
      CHECKERS: ${{ inputs.CHECKERS }}
      CHUNK_SIZE: ${{ inputs.CHUNK_SIZE }}

    steps:
      - name: Install rclone (latest version)
        run: |
          set -e
          curl -fsSL https://rclone.org/install.sh | sudo bash
          rclone version
          echo "rclone安装完成"

      - name: Prepare optimized rclone config
        run: |
          set -e
          mkdir -p ~/.config/rclone

          cat > ~/.config/rclone/rclone.conf <<EOF
          [r2src]
          type = s3
          provider = Cloudflare
          access_key_id = ${R2PUSH_ACCESS_KEY}
          secret_access_key = ${R2PUSH_SECRET_KEY}
          endpoint = ${R2PUSH_ENDPOINT}
          force_path_style = true
          acl = private
          chunk_size = ${CHUNK_SIZE}
          upload_cutoff = ${CHUNK_SIZE}
          no_check_bucket = true

          [r2dst]
          type = s3
          provider = Cloudflare
          access_key_id = ${R2DST_ACCESS_KEY}
          secret_access_key = ${R2DST_SECRET_KEY}
          endpoint = ${R2DST_ENDPOINT}
          force_path_style = true
          acl = private
          chunk_size = ${CHUNK_SIZE}
          upload_cutoff = ${CHUNK_SIZE}
          no_check_bucket = true
          EOF

          echo "✅ rclone.conf已生成"
        env:
          R2PUSH_ACCESS_KEY: ${{ secrets.R2PUSH_ACCESS_KEY }}
          R2PUSH_SECRET_KEY: ${{ secrets.R2PUSH_SECRET_KEY }}
          R2PUSH_ENDPOINT: ${{ secrets.R2PUSH_ENDPOINT }}
          R2DST_ACCESS_KEY: ${{ secrets.R2DST_ACCESS_KEY }}
          R2DST_SECRET_KEY: ${{ secrets.R2DST_SECRET_KEY }}
          R2DST_ENDPOINT: ${{ secrets.R2DST_ENDPOINT }}
          CHUNK_SIZE: ${{ inputs.CHUNK_SIZE }}

      - name: Create high-performance migration script
        run: |
          set -e
          cat > /tmp/migrate.sh <<'EOF'
          #!/bin/bash
          set -e

          # 高性能迁移参数（已验证的有效参数）
          COMMON_ARGS="--progress --log-level INFO --stats=60s --stats-one-line \
          --transfers=${TRANSFERS} --checkers=${CHECKERS} \
          --s3-upload-cutoff=${CHUNK_SIZE} --s3-chunk-size=${CHUNK_SIZE} \
          --checksum --size-only --no-check-dest \
          --retries=10 --retries-sleep=30s --low-level-retries=20 \
          --timeout=300s --contimeout=120s \
          --buffer-size=512M --use-mmap \
          --multi-thread-streams=8 --multi-thread-cutoff=64M \
          --fast-list --no-traverse --no-update-modtime \
          --s3-disable-checksum --disable-http2"

          echo "开始高性能迁移"
          echo "参数: transfers=${TRANSFERS}, checkers=${CHECKERS}, chunk_size=${CHUNK_SIZE}"
          echo "当前时间: $(date)"
          echo "系统信息: $(uname -a)"

          MAX_RETRIES=20
          ATTEMPT=1
          RC=1

          while [ $ATTEMPT -le $MAX_RETRIES ] && [ $RC -ne 0 ]; do
            echo "=== 尝试第 $ATTEMPT/$MAX_RETRIES 次迁移 ==="
            echo "开始时间: $(date)"
            
            # 保存状态信息
            echo "ATTEMPT:$ATTEMPT" > /tmp/last_attempt.txt
            
            if [[ "${MODE}" == "sync" ]]; then
              rclone sync r2src:"${SRC_BUCKET}" r2dst:"${DST_BUCKET}" $COMMON_ARGS --delete-after 2>&1 | tee /tmp/migration-log-${ATTEMPT}.txt
            else
              rclone copy r2src:"${SRC_BUCKET}" r2dst:"${DST_BUCKET}" $COMMON_ARGS 2>&1 | tee /tmp/migration-log-${ATTEMPT}.txt
            fi
            
            RC=${PIPESTATUS[0]}
            
            if [ $RC -eq 0 ]; then
              echo "✅ 迁移成功完成"
              break
            else
              echo "❌ 迁移失败 (代码: $RC)，等待重试..."
              sleep 60
            fi
            
            ATTEMPT=$((ATTEMPT + 1))
          done

          if [ $RC -ne 0 ]; then
            echo "❌ 所有重试尝试均失败"
            exit $RC
          fi
          
          echo "🎉 迁移完成！"
          EOF

          chmod +x /tmp/migrate.sh
        env:
          TRANSFERS: ${{ inputs.TRANSFERS }}
          CHECKERS: ${{ inputs.CHECKERS }}
          CHUNK_SIZE: ${{ inputs.CHUNK_SIZE }}

      - name: Run high-performance migration
        run: |
          set -e
          echo "== 执行高性能迁移 =="
          echo "并发设置: ${TRANSFERS}传输/${CHECKERS}校验"
          echo "分块大小: ${CHUNK_SIZE}"
          
          # 显示系统信息
          echo "CPU核心数: $(nproc)"
          echo "内存总量: $(free -h | awk '/Mem:/{print $2}')"
          
          # 执行迁移
          /tmp/migrate.sh

      - name: Quick verification
        run: |
          set -e
          echo "== 快速验证 =="
          
          echo "文件数量对比:"
          SRC_COUNT=$(rclone lsf r2src:"${SRC_BUCKET}" | wc -l || echo "N/A")
          DST_COUNT=$(rclone lsf r2dst:"${DST_BUCKET}" | wc -l || echo "N/A")
          echo "源桶: $SRC_COUNT 文件 | 目标桶: $DST_COUNT 文件"
          
          echo "随机抽查10个文件:"
          for i in $(seq 1 10); do
            file=$(rclone lsf r2src:"${SRC_BUCKET}" | grep -v "/$" | shuf -n 1)
            if [ -n "$file" ]; then
              src_size=$(rclone size r2src:"${SRC_BUCKET}/$file" --json 2>/dev/null | jq -r '.bytes // "N/A"' || echo "N/A")
              dst_size=$(rclone size r2dst:"${DST_BUCKET}/$file" --json 2>/dev/null | jq -r '.bytes // "N/A"' || echo "N/A")
              
              if [ "$src_size" = "N/A" ] || [ "$dst_size" = "N/A" ]; then
                echo "⚠️  $file - 无法获取大小"
              elif [ "$src_size" = "$dst_size" ]; then
                echo "✅ $file - 一致 ($src_size bytes)"
              else
                echo "❌ $file - 大小不一致: 源=$src_size, 目标=$dst_size"
              fi
            fi
          done

      - name: Final report
        if: always()
        run: |
          {
            echo "### R2迁移报告"
            echo "- **状态**: ${{ job.status }}"
            echo "- **模式**: \`${MODE}\`"
            echo "- **源桶**: \`${SRC_BUCKET}\`"
            echo "- **目标桶**: \`${DST_BUCKET}\`"
            echo "- **并发**: ${TRANSFERS}传输/${CHECKERS}校验"
            echo "- **分块大小**: ${CHUNK_SIZE}"
            echo ""
            echo "#### 统计信息"
            echo "\`\`\`"
            echo "源桶统计:"
            rclone size r2src:"${SRC_BUCKET}" --json 2>/dev/null | jq . || echo "无法获取源桶统计"
            echo ""
            echo "目标桶统计:"
            rclone size r2dst:"${DST_BUCKET}" --json 2>/dev/null | jq . || echo "无法获取目标桶统计"
            echo "\`\`\`"
          } >> $GITHUB_STEP_SUMMARY

      - name: Upload logs for debugging
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: migration-logs
          path: |
            /tmp/migration-log-*.txt
            /tmp/last_attempt.txt
          retention-days: 7
