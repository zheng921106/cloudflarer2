name: Cloudflare R2 Bucket Migration (rclone) - Ultimate Fix

on:
  workflow_dispatch:
    inputs:
      SRC_BUCKET:
        description: "Aæ¡¶åç§°ï¼ˆæ¥æºæ¡¶åï¼‰"
        required: true
        type: string
        default: "yasyadong001"
      DST_BUCKET:
        description: "Bæ¡¶åç§°ï¼ˆç›®æ ‡æ¡¶åï¼‰"
        required: true
        type: string
        default: "yas009"
      MODE:
        description: "è¿ç§»æ¨¡å¼"
        required: true
        default: "copy"
        type: choice
        options: ["copy", "sync"]
      TRANSFERS:
        description: "å¹¶å‘ä¼ è¾“æ•°"
        required: true
        default: "8"  # å¤§å¹…é™ä½å¹¶å‘
        type: string
      CHECKERS:
        description: "å¹¶å‘æ ¡éªŒæ•°"
        required: true
        default: "16"  # é™ä½æ ¡éªŒå¹¶å‘
        type: string
      RESUME:
        description: "æ–­ç‚¹ç»­ä¼ æ¨¡å¼"
        required: true
        default: "true"
        type: choice
        options: ["true", "false"]

jobs:
  migrate:
    name: Ultimate R2 Migration
    runs-on: ubuntu-latest
    timeout-minutes: 8640  # 6å¤©è¶…æ—¶ï¼Œ15TBéœ€è¦å¾ˆé•¿æ—¶é—´
    env:
      SRC_BUCKET: ${{ inputs.SRC_BUCKET }}
      DST_BUCKET: ${{ inputs.DST_BUCKET }}
      MODE: ${{ inputs.MODE }}
      TRANSFERS: ${{ inputs.TRANSFERS }}
      CHECKERS: ${{ inputs.CHECKERS }}
      RESUME: ${{ inputs.RESUME }}

    steps:
      - name: Install rclone and tools
        run: |
          set -e
          # å®‰è£…æœ€æ–°ç‰ˆrclone
          curl -fsSL https://rclone.org/install.sh | sudo bash -s beta
          rclone version
          
          # å®‰è£…ç›‘æ§å·¥å…·
          sudo apt-get update
          sudo apt-get install -y htop iotop nethogs

      - name: Prepare robust rclone config
        run: |
          set -e
          mkdir -p ~/.config/rclone

          cat > ~/.config/rclone/rclone.conf <<EOF
          [r2src]
          type = s3
          provider = Cloudflare
          access_key_id = ${R2PUSH_ACCESS_KEY}
          secret_access_key = ${R2PUSH_SECRET_KEY}
          endpoint = ${R2PUSH_ENDPOINT}
          force_path_style = true
          acl = private
          # å…³é”®ä¿®å¤å‚æ•°
          chunk_size = 32M
          upload_cutoff = 32M
          disable_checksum = false
          memory_pool_flush_time = 60s
          memory_pool_use_mmap = true
          no_check_bucket = true
          # è¿æ¥ä¼˜åŒ–
          timeout = 600s
          connect_timeout = 300s
          expect_continue_timeout = 60s

          [r2dst]
          type = s3
          provider = Cloudflare
          access_key_id = ${R2DST_ACCESS_KEY}
          secret_access_key = ${R2DST_SECRET_KEY}
          endpoint = ${R2DST_ENDPOINT}
          force_path_style = true
          acl = private
          # å…³é”®ä¿®å¤å‚æ•°
          chunk_size = 32M
          upload_cutoff = 32M
          disable_checksum = false
          memory_pool_flush_time = 60s
          memory_pool_use_mmap = true
          no_check_bucket = true
          # è¿æ¥ä¼˜åŒ–
          timeout = 600s
          connect_timeout = 300s
          expect_continue_timeout = 60s
          EOF

          echo "âœ… rclone.conf å·²ç”Ÿæˆï¼ˆåŒ…å«ç¨³å®šæ€§ä¼˜åŒ–ï¼‰"
        env:
          R2PUSH_ACCESS_KEY: ${{ secrets.R2PUSH_ACCESS_KEY }}
          R2PUSH_SECRET_KEY: ${{ secrets.R2PUSH_SECRET_KEY }}
          R2PUSH_ENDPOINT: ${{ secrets.R2PUSH_ENDPOINT }}
          R2DST_ACCESS_KEY: ${{ secrets.R2DST_ACCESS_KEY }}
          R2DST_SECRET_KEY: ${{ secrets.R2DST_SECRET_KEY }}
          R2DST_ENDPOINT: ${{ secrets.R2DST_ENDPOINT }}

      - name: Preflight deep check
        run: |
          set -e
          echo "== æ·±åº¦é¢„æ£€æ£€æŸ¥ =="
          
          # æ£€æŸ¥ç½‘ç»œè¿é€šæ€§
          echo "æµ‹è¯•æºç«¯ç‚¹è¿é€šæ€§..."
          curl -s -o /dev/null -w "HTTP Code: %{http_code}\n" ${R2PUSH_ENDPOINT} || true
          
          echo "æµ‹è¯•ç›®æ ‡ç«¯ç‚¹è¿é€šæ€§..."
          curl -s -o /dev/null -w "HTTP Code: %{http_code}\n" ${R2DST_ENDPOINT} || true
          
          # æ£€æŸ¥æ¡¶æƒé™
          echo "æ£€æŸ¥æºæ¡¶åˆ—è¡¨æƒé™..."
          rclone lsd r2src: --max-depth 1 || echo "åˆ—è¡¨æƒé™æ£€æŸ¥å¤±è´¥"
          
          echo "æ£€æŸ¥ç›®æ ‡æ¡¶åˆ—è¡¨æƒé™..."
          rclone lsd r2dst: --max-depth 1 || echo "åˆ—è¡¨æƒé™æ£€æŸ¥å¤±è´¥"

      - name: Create migration script with retry logic
        run: |
          set -e
          cat > /tmp/migrate.sh <<'EOF'
          #!/bin/bash
          set -e

          # è¿ç§»å‚æ•° - é’ˆå¯¹æ–‡ä»¶æŸåé—®é¢˜çš„ä¸“é—¨ä¿®å¤
          COMMON_ARGS="--progress --verbose --log-level INFO --stats=60s --stats-one-line \
          --transfers=${TRANSFERS} --checkers=${CHECKERS} \
          --s3-upload-cutoff=32M --s3-chunk-size=32M \
          --checksum --size-only --compare-dest=checksum \
          --retries=20 --retries-sleep=60s --low-level-retries=50 \
          --timeout=600s --contimeout=300s \
          --buffer-size=128M --use-mmap \
          --multi-thread-streams=2 --multi-thread-cutoff=16M \
          --fast-list --no-traverse --no-update-modtime \
          --s3-disable-checksum --disable-http2"

          # æ–­ç‚¹ç»­ä¼ æ”¯æŒ
          if [ "$RESUME" = "true" ]; then
            COMMON_ARGS="$COMMON_ARGS --backup-dir=r2dst:${DST_BUCKET}-backup/retry-files"
          fi

          echo "å¼€å§‹è¿ç§» - å‚æ•°: $COMMON_ARGS"
          echo "å½“å‰æ—¶é—´: $(date)"

          MAX_RETRIES=3
          ATTEMPT=1
          RC=1

          while [ $ATTEMPT -le $MAX_RETRIES ] && [ $RC -ne 0 ]; do
            echo "=== å°è¯•ç¬¬ $ATTEMPT/$MAX_RETRIES æ¬¡è¿ç§» ==="
            
            if [[ "${MODE}" == "sync" ]]; then
              rclone sync r2src:"${SRC_BUCKET}" r2dst:"${DST_BUCKET}" $COMMON_ARGS --delete-after
            else
              rclone copy r2src:"${SRC_BUCKET}" r2dst:"${DST_BUCKET}" $COMMON_ARGS
            fi
            
            RC=$?
            
            if [ $RC -eq 0 ]; then
              echo "âœ… è¿ç§»æˆåŠŸå®Œæˆ"
              break
            elif [ $RC -eq 9 ]; then
              echo "âš ï¸  ä¼ è¾“è¢«ä¸­æ–­ï¼Œè¿›è¡Œé‡è¯•..."
              sleep 120
            else
              echo "âŒ è¿ç§»å¤±è´¥ (ä»£ç : $RC)ï¼Œç­‰å¾…é‡è¯•..."
              sleep 300
            fi
            
            ATTEMPT=$((ATTEMPT + 1))
          done

          if [ $RC -ne 0 ]; then
            echo "âŒ æ‰€æœ‰é‡è¯•å°è¯•å‡å¤±è´¥"
            exit $RC
          fi
          EOF

          chmod +x /tmp/migrate.sh
        env:
          TRANSFERS: ${{ inputs.TRANSFERS }}
          CHECKERS: ${{ inputs.CHECKERS }}
          RESUME: ${{ inputs.RESUME }}

      - name: Run migration with monitoring
        run: |
          set -e
          echo "== å¯åŠ¨ç³»ç»Ÿç›‘æ§ =="
          
          # åå°ç›‘æ§è¿›ç¨‹
          htop -d 10 > /tmp/htop.log 2>&1 &
          iotop -bot -d 10 > /tmp/iotop.log 2>&1 &
          nethogs -d 10 -c 100 > /tmp/nethogs.log 2>&1 &
          
          # æ‰§è¡Œè¿ç§»è„šæœ¬
          /tmp/migrate.sh
          
          echo "âœ… è¿ç§»æ‰§è¡Œå®Œæˆ"

      - name: Post-migration integrity verification
        run: |
          set -e
          echo "== è¿ç§»åå®Œæ•´æ€§æ·±åº¦éªŒè¯ =="
          
          # æ£€æŸ¥0å­—èŠ‚æ–‡ä»¶ï¼ˆä¿®å¤æ–‡ä»¶æŸåé—®é¢˜ï¼‰
          echo "æ£€æŸ¥ç›®æ ‡æ¡¶ä¸­çš„0å­—èŠ‚æ–‡ä»¶:"
          rclone ls r2dst:"${DST_BUCKET}" --max-depth 5 | grep -E "^\s+0 " | head -n 20 || echo "æœªå‘ç°0å­—èŠ‚æ–‡ä»¶"
          
          # å¯¹æ¯”æ–‡ä»¶æ•°é‡
          echo "æ–‡ä»¶æ•°é‡å¯¹æ¯”:"
          SRC_COUNT=$(rclone ls r2src:"${SRC_BUCKET}" | wc -l || echo "N/A")
          DST_COUNT=$(rclone ls r2dst:"${DST_BUCKET}" | wc -l || echo "N/A")
          echo "æºæ¡¶: $SRC_COUNT æ–‡ä»¶ | ç›®æ ‡æ¡¶: $DST_COUNT æ–‡ä»¶"
          
          # æŠ½æ ·æ£€æŸ¥100ä¸ªæ–‡ä»¶
          echo "éšæœºæŠ½æ ·æ£€æŸ¥100ä¸ªæ–‡ä»¶çš„å¤§å°ä¸€è‡´æ€§:"
          SAMPLE_FILES=$(rclone lsf r2src:"${SRC_BUCKET}" -R --files-only | shuf -n 100)
          CORRUPTED_COUNT=0
          
          for file in $SAMPLE_FILES; do
            if [ -n "$file" ]; then
              src_size=$(rclone size r2src:"${SRC_BUCKET}/$file" --json 2>/dev/null | jq -r '.bytes // "ERROR"' || echo "ERROR")
              dst_size=$(rclone size r2dst:"${DST_BUCKET}/$file" --json 2>/dev/null | jq -r '.bytes // "ERROR"' || echo "ERROR")
              
              if [ "$src_size" = "ERROR" ] || [ "$dst_size" = "ERROR" ]; then
                echo "âŒ $file - æ£€æŸ¥é”™è¯¯"
                CORRUPTED_COUNT=$((CORRUPTED_COUNT + 1))
              elif [ "$src_size" != "$dst_size" ]; then
                echo "âŒ $file - å¤§å°ä¸ä¸€è‡´: æº=$src_size, ç›®æ ‡=$dst_size"
                CORRUPTED_COUNT=$((CORRUPTED_COUNT + 1))
              else
                echo "âœ… $file - ä¸€è‡´ ($src_size bytes)"
              fi
            fi
          done
          
          echo "æŸåæ–‡ä»¶æ¯”ä¾‹: $CORRUPTED_COUNT/100"
          
          if [ $CORRUPTED_COUNT -gt 5 ]; then
            echo "âš ï¸  æ£€æµ‹åˆ°è¾ƒå¤šæ–‡ä»¶æŸåï¼Œå»ºè®®é‡æ–°è¿è¡Œè¿ç§»"
            exit 1
          fi

      - name: Final summary and cleanup
        if: always()
        run: |
          {
            echo "### ğŸ‰ R2è¿ç§»æœ€ç»ˆæŠ¥å‘Š"
            echo "- **çŠ¶æ€**: $(if [ $? -eq 0 ]; then echo 'âœ… æˆåŠŸ'; else echo 'âŒ å¤±è´¥'; fi)"
            echo "- **æ¨¡å¼**: \`${MODE}\`"
            echo "- **æºæ¡¶**: \`${SRC_BUCKET}\`"
            echo "- **ç›®æ ‡æ¡¶**: \`${DST_BUCKET}\`"
            echo "- **å¹¶å‘**: ${TRANSFERS}ä¼ è¾“/${CHECKERS}æ ¡éªŒ"
            echo "- **æ–­ç‚¹ç»­ä¼ **: ${RESUME}"
            echo ""
            echo "#### ç»Ÿè®¡ä¿¡æ¯"
            echo "\`\`\`"
            echo "æºæ¡¶:"
            rclone size r2src:"${SRC_BUCKET}" --json 2>/dev/null | jq || echo "æ— æ³•è·å–ç»Ÿè®¡"
            echo ""
            echo "ç›®æ ‡æ¡¶:"
            rclone size r2dst:"${DST_BUCKET}" --json 2>/dev/null | jq || echo "æ— æ³•è·å–ç»Ÿè®¡"
            echo "\`\`\`"
            echo ""
            echo "#### ç³»ç»Ÿç›‘æ§æ‘˜è¦"
            echo "\`\`\`"
            tail -n 20 /tmp/htop.log 2>/dev/null || echo "æ— ç›‘æ§æ•°æ®"
            echo "\`\`\`"
          } >> $GITHUB_STEP_SUMMARY
          
          # æ¸…ç†ç›‘æ§è¿›ç¨‹
          pkill -f htop || true
          pkill -f iotop || true
          pkill -f nethogs || true
