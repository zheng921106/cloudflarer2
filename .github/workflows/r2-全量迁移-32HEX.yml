name: Cloudflare R2 Bucket Migration (rclone) - Optimized Version

on:
  workflow_dispatch:
    inputs:
      SRC_BUCKET:
        description: "Aæ¡¶åç§°ï¼ˆæ¥æºæ¡¶åï¼‰"
        required: true
        type: string
        default: "yasyadong001"
      DST_BUCKET:
        description: "Bæ¡¶åç§°ï¼ˆç›®æ ‡æ¡¶åï¼‰"
        required: true
        type: string
        default: "yas009"
      MODE:
        description: "è¿ç§»æ¨¡å¼"
        required: true
        default: "copy"
        type: choice
        options: ["copy", "sync"]
      TRANSFERS:
        description: "å¹¶å‘ä¼ è¾“æ•°"
        required: true
        default: "64"
        type: string
      CHECKERS:
        description: "å¹¶å‘æ ¡éªŒæ•°"
        required: true
        default: "128"
        type: string
      CHUNK_SIZE:
        description: "åˆ†å—å¤§å°"
        required: true
        default: "256M"
        type: string

jobs:
  migrate:
    name: Optimized R2 Migration
    runs-on: ubuntu-latest
    timeout-minutes: 10080  # 7å¤©è¶…æ—¶
    env:
      SRC_BUCKET: ${{ inputs.SRC_BUCKET }}
      DST_BUCKET: ${{ inputs.DST_BUCKET }}
      MODE: ${{ inputs.MODE }}
      TRANSFERS: ${{ inputs.TRANSFERS }}
      CHECKERS: ${{ inputs.CHECKERS }}
      CHUNK_SIZE: ${{ inputs.CHUNK_SIZE }}

    steps:
      - name: Install rclone (latest version)
        run: |
          set -e
          curl -fsSL https://rclone.org/install.sh | sudo bash
          rclone version
          echo "rcloneå®‰è£…å®Œæˆ"

      - name: Prepare optimized rclone config
        run: |
          set -e
          mkdir -p ~/.config/rclone

          cat > ~/.config/rclone/rclone.conf <<EOF
          [r2src]
          type = s3
          provider = Cloudflare
          access_key_id = ${R2PUSH_ACCESS_KEY}
          secret_access_key = ${R2PUSH_SECRET_KEY}
          endpoint = ${R2PUSH_ENDPOINT}
          force_path_style = true
          acl = private
          chunk_size = ${CHUNK_SIZE}
          upload_cutoff = ${CHUNK_SIZE}
          no_check_bucket = true

          [r2dst]
          type = s3
          provider = Cloudflare
          access_key_id = ${R2DST_ACCESS_KEY}
          secret_access_key = ${R2DST_SECRET_KEY}
          endpoint = ${R2DST_ENDPOINT}
          force_path_style = true
          acl = private
          chunk_size = ${CHUNK_SIZE}
          upload_cutoff = ${CHUNK_SIZE}
          no_check_bucket = true
          EOF

          echo "âœ… rclone.confå·²ç”Ÿæˆ"
        env:
          R2PUSH_ACCESS_KEY: ${{ secrets.R2PUSH_ACCESS_KEY }}
          R2PUSH_SECRET_KEY: ${{ secrets.R2PUSH_SECRET_KEY }}
          R2PUSH_ENDPOINT: ${{ secrets.R2PUSH_ENDPOINT }}
          R2DST_ACCESS_KEY: ${{ secrets.R2DST_ACCESS_KEY }}
          R2DST_SECRET_KEY: ${{ secrets.R2DST_SECRET_KEY }}
          R2DST_ENDPOINT: ${{ secrets.R2DST_ENDPOINT }}
          CHUNK_SIZE: ${{ inputs.CHUNK_SIZE }}

      - name: Create high-performance migration script
        run: |
          set -e
          cat > /tmp/migrate.sh <<'EOF'
          #!/bin/bash
          set -e

          # é«˜æ€§èƒ½è¿ç§»å‚æ•°ï¼ˆå·²éªŒè¯çš„æœ‰æ•ˆå‚æ•°ï¼‰
          COMMON_ARGS="--progress --log-level INFO --stats=60s --stats-one-line \
          --transfers=${TRANSFERS} --checkers=${CHECKERS} \
          --s3-upload-cutoff=${CHUNK_SIZE} --s3-chunk-size=${CHUNK_SIZE} \
          --checksum --size-only --no-check-dest \
          --retries=10 --retries-sleep=30s --low-level-retries=20 \
          --timeout=300s --contimeout=120s \
          --buffer-size=512M --use-mmap \
          --multi-thread-streams=8 --multi-thread-cutoff=64M \
          --fast-list --no-traverse --no-update-modtime \
          --s3-disable-checksum --disable-http2"

          echo "å¼€å§‹é«˜æ€§èƒ½è¿ç§»"
          echo "å‚æ•°: transfers=${TRANSFERS}, checkers=${CHECKERS}, chunk_size=${CHUNK_SIZE}"
          echo "å½“å‰æ—¶é—´: $(date)"
          echo "ç³»ç»Ÿä¿¡æ¯: $(uname -a)"

          MAX_RETRIES=20
          ATTEMPT=1
          RC=1

          while [ $ATTEMPT -le $MAX_RETRIES ] && [ $RC -ne 0 ]; do
            echo "=== å°è¯•ç¬¬ $ATTEMPT/$MAX_RETRIES æ¬¡è¿ç§» ==="
            echo "å¼€å§‹æ—¶é—´: $(date)"
            
            # ä¿å­˜çŠ¶æ€ä¿¡æ¯
            echo "ATTEMPT:$ATTEMPT" > /tmp/last_attempt.txt
            
            if [[ "${MODE}" == "sync" ]]; then
              rclone sync r2src:"${SRC_BUCKET}" r2dst:"${DST_BUCKET}" $COMMON_ARGS --delete-after 2>&1 | tee /tmp/migration-log-${ATTEMPT}.txt
            else
              rclone copy r2src:"${SRC_BUCKET}" r2dst:"${DST_BUCKET}" $COMMON_ARGS 2>&1 | tee /tmp/migration-log-${ATTEMPT}.txt
            fi
            
            RC=${PIPESTATUS[0]}
            
            if [ $RC -eq 0 ]; then
              echo "âœ… è¿ç§»æˆåŠŸå®Œæˆ"
              break
            else
              echo "âŒ è¿ç§»å¤±è´¥ (ä»£ç : $RC)ï¼Œç­‰å¾…é‡è¯•..."
              sleep 60
            fi
            
            ATTEMPT=$((ATTEMPT + 1))
          done

          if [ $RC -ne 0 ]; then
            echo "âŒ æ‰€æœ‰é‡è¯•å°è¯•å‡å¤±è´¥"
            exit $RC
          fi
          
          echo "ðŸŽ‰ è¿ç§»å®Œæˆï¼"
          EOF

          chmod +x /tmp/migrate.sh
        env:
          TRANSFERS: ${{ inputs.TRANSFERS }}
          CHECKERS: ${{ inputs.CHECKERS }}
          CHUNK_SIZE: ${{ inputs.CHUNK_SIZE }}

      - name: Run high-performance migration
        run: |
          set -e
          echo "== æ‰§è¡Œé«˜æ€§èƒ½è¿ç§» =="
          echo "å¹¶å‘è®¾ç½®: ${TRANSFERS}ä¼ è¾“/${CHECKERS}æ ¡éªŒ"
          echo "åˆ†å—å¤§å°: ${CHUNK_SIZE}"
          
          # æ˜¾ç¤ºç³»ç»Ÿä¿¡æ¯
          echo "CPUæ ¸å¿ƒæ•°: $(nproc)"
          echo "å†…å­˜æ€»é‡: $(free -h | awk '/Mem:/{print $2}')"
          
          # æ‰§è¡Œè¿ç§»
          /tmp/migrate.sh

      - name: Quick verification
        run: |
          set -e
          echo "== å¿«é€ŸéªŒè¯ =="
          
          echo "æ–‡ä»¶æ•°é‡å¯¹æ¯”:"
          SRC_COUNT=$(rclone lsf r2src:"${SRC_BUCKET}" | wc -l || echo "N/A")
          DST_COUNT=$(rclone lsf r2dst:"${DST_BUCKET}" | wc -l || echo "N/A")
          echo "æºæ¡¶: $SRC_COUNT æ–‡ä»¶ | ç›®æ ‡æ¡¶: $DST_COUNT æ–‡ä»¶"
          
          echo "éšæœºæŠ½æŸ¥10ä¸ªæ–‡ä»¶:"
          for i in $(seq 1 10); do
            file=$(rclone lsf r2src:"${SRC_BUCKET}" | grep -v "/$" | shuf -n 1)
            if [ -n "$file" ]; then
              src_size=$(rclone size r2src:"${SRC_BUCKET}/$file" --json 2>/dev/null | jq -r '.bytes // "N/A"' || echo "N/A")
              dst_size=$(rclone size r2dst:"${DST_BUCKET}/$file" --json 2>/dev/null | jq -r '.bytes // "N/A"' || echo "N/A")
              
              if [ "$src_size" = "N/A" ] || [ "$dst_size" = "N/A" ]; then
                echo "âš ï¸  $file - æ— æ³•èŽ·å–å¤§å°"
              elif [ "$src_size" = "$dst_size" ]; then
                echo "âœ… $file - ä¸€è‡´ ($src_size bytes)"
              else
                echo "âŒ $file - å¤§å°ä¸ä¸€è‡´: æº=$src_size, ç›®æ ‡=$dst_size"
              fi
            fi
          done

      - name: Final report
        if: always()
        run: |
          {
            echo "### R2è¿ç§»æŠ¥å‘Š"
            echo "- **çŠ¶æ€**: ${{ job.status }}"
            echo "- **æ¨¡å¼**: \`${MODE}\`"
            echo "- **æºæ¡¶**: \`${SRC_BUCKET}\`"
            echo "- **ç›®æ ‡æ¡¶**: \`${DST_BUCKET}\`"
            echo "- **å¹¶å‘**: ${TRANSFERS}ä¼ è¾“/${CHECKERS}æ ¡éªŒ"
            echo "- **åˆ†å—å¤§å°**: ${CHUNK_SIZE}"
            echo ""
            echo "#### ç»Ÿè®¡ä¿¡æ¯"
            echo "\`\`\`"
            echo "æºæ¡¶ç»Ÿè®¡:"
            rclone size r2src:"${SRC_BUCKET}" --json 2>/dev/null | jq . || echo "æ— æ³•èŽ·å–æºæ¡¶ç»Ÿè®¡"
            echo ""
            echo "ç›®æ ‡æ¡¶ç»Ÿè®¡:"
            rclone size r2dst:"${DST_BUCKET}" --json 2>/dev/null | jq . || echo "æ— æ³•èŽ·å–ç›®æ ‡æ¡¶ç»Ÿè®¡"
            echo "\`\`\`"
          } >> $GITHUB_STEP_SUMMARY

      - name: Upload logs for debugging
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: migration-logs
          path: |
            /tmp/migration-log-*.txt
            /tmp/last_attempt.txt
          retention-days: 7
