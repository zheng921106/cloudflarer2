name: R2 全量迁移（自动发现 32 位十六进制目录，不校验）

on:
  workflow_dispatch: {}
  # 如需定时续跑（UTC），取消注释
  # schedule:
  #   - cron: "0 * * * *"

env:
  # 桶名
  SRC_BUCKET: yasyadong001
  DST_BUCKET: yas004

  # 如果这些 32 位目录不在桶根，而是在某个固定前缀下（例如 "video"），这里填前缀；否则留空
  ROOT_PREFIX: ""

  # 吞吐参数（先稳后快，视情况调整）
  TRANSFERS: "6"
  CHECKERS: "16"
  UPLOAD_CONC: "4"
  BW_LIMIT: "0"          # 不限速；如需限速改 "10M"
  TPS_LIMIT: "16"        # 如遇 429/503 可下调
  CHUNK_SIZE: "32M"
  COPY_CUTOFF: "256M"
  MAX_RETRIES: "8"
  LOW_LEVEL_RETRIES: "20"
  # 如要避免搬运“正在写入”的半成品，可开启：
  # MIN_AGE: "60s"

jobs:
  migrate:
    runs-on: ubuntu-latest
    timeout-minutes: 360
    strategy:
      fail-fast: false
      matrix:
        shard: [ "0","1","2","3","4","5","6","7","8","9","A","B","C","D","E","F" ]

    steps:
      - name: 安装 rclone
        run: |
          curl -fsSL https://rclone.org/install.sh | sudo bash
          rclone version

      - name: 配置 R2 源与目标
        env:
          R2PUSH_ACCESS_KEY:  ${{ secrets.R2PUSH_ACCESS_KEY }}
          R2PUSH_SECRET_KEY:  ${{ secrets.R2PUSH_SECRET_KEY }}
          R2PUSH_ENDPOINT:    ${{ secrets.R2PUSH_ENDPOINT }}
          R2DST_ACCESS_KEY:   ${{ secrets.R2DST_ACCESS_KEY }}
          R2DST_SECRET_KEY:   ${{ secrets.R2DST_SECRET_KEY }}
          R2DST_ENDPOINT:     ${{ secrets.R2DST_ENDPOINT }}
        run: |
          set -euo pipefail
          rclone config create r2src s3 \
            provider=Other env_auth=false \
            access_key_id="${R2PUSH_ACCESS_KEY}" secret_access_key="${R2PUSH_SECRET_KEY}" \
            region=auto endpoint="${R2PUSH_ENDPOINT}" \
            s3-chunk-size="${CHUNK_SIZE}" s3-upload-concurrency="${UPLOAD_CONC}"
          rclone config create r2dst s3 \
            provider=Other env_auth=false \
            access_key_id="${R2DST_ACCESS_KEY}" secret_access_key="${R2DST_SECRET_KEY}" \
            region=auto endpoint="${R2DST_ENDPOINT}" \
            s3-chunk-size="${CHUNK_SIZE}" s3-upload-concurrency="${UPLOAD_CONC}"
          rclone listremotes

      - name: 确保目标桶存在
        run: |
          set -euo pipefail
          if ! rclone lsd "r2dst:" | grep -qE "\s${DST_BUCKET}\s*$"; then
            echo "创建目标桶：${DST_BUCKET}"
            rclone mkdir "r2dst:${DST_BUCKET}"
          else
            echo "目标桶已存在：${DST_BUCKET}"
          fi

      # 只列举“当前分片首字符”的顶层目录，筛出 32 位十六进制目录，生成过滤规则
      - name: 生成分片过滤规则（仅 32 位十六进制目录）
        id: buildfilter
        run: |
          set -euo pipefail
          mkdir -p filters
          FILTER="filters/${{ matrix.shard }}.filter"
          : > "$FILTER"

          # 计算列举基路径：桶根 或 桶根/前缀
          BASE="r2src:${SRC_BUCKET}"
          if [ -n "${ROOT_PREFIX}" ]; then
            BASE="${BASE}/${ROOT_PREFIX%/}"
          fi

          # 只列举当前首字符的顶层“目录”
          rclone lsf "${BASE}/${{ matrix.shard }}" --dirs-only --max-depth 1 > shard_dirs.txt || true

          # 筛出：目录名为 32 位十六进制，大小写均可（行以 / 结尾）
          awk '
            BEGIN{ IGNORECASE=1 }
            /^[0-9A-F]{32}\/$/ { print }
          ' shard_dirs.txt > matched_dirs.txt

          echo "本分片匹配目录（最多显示 50 条）："
          head -50 matched_dirs.txt || true
          cnt=$(wc -l < matched_dirs.txt | tr -d " ")

          # 生成 rclone 过滤规则；需要把 ROOT_PREFIX（如有）拼回去
          if [ "$cnt" -gt 0 ]; then
            if [ -n "${ROOT_PREFIX}" ]; then
              while IFS= read -r d; do
                printf "+ %s/%s**\n" "${ROOT_PREFIX%/}" "$d"
              done < matched_dirs.txt > "$FILTER"
            else
              while IFS= read -r d; do
                printf "+ %s**\n" "$d"
              done < matched_dirs.txt > "$FILTER"
            fi
            echo "- **" >> "$FILTER"
            echo "file=$FILTER" >> "$GITHUB_OUTPUT"
            echo "empty=false" >> "$GITHUB_OUTPUT"
          else
            echo "# empty shard" > "$FILTER"
            echo "file=$FILTER" >> "$GITHUB_OUTPUT"
            echo "empty=true" >> "$GITHUB_OUTPUT"
          fi

      - name: 执行迁移（不校验）
        if: steps.buildfilter.outputs.empty == 'false'
        run: |
          set -euo pipefail
          mkdir -p logs
          LOG="logs/migrate_${{ matrix.shard }}_$(date -u +%F_%H-%M-%S).log"
          echo "开始迁移：分片=${{ matrix.shard }}  规则=${{ steps.buildfilter.outputs.file }}" | tee -a "$LOG"

          rclone copy "r2src:${SRC_BUCKET}" "r2dst:${DST_BUCKET}" \
            --fast-list --metadata \
            --filter-from "${{ steps.buildfilter.outputs.file }}" \
            --transfers "${TRANSFERS}" --checkers "${CHECKERS}" \
            --bwlimit "${BW_LIMIT}" --tpslimit "${TPS_LIMIT}" \
            --s3-chunk-size "${CHUNK_SIZE}" --s3-copy-cutoff "${COPY_CUTOFF}" \
            --retries "${MAX_RETRIES}" --low-level-retries "${LOW_LEVEL_RETRIES}" \
            --progress 2>&1 | tee -a "$LOG"
            # 如需避开“正在写入”的文件，取消下一行注释：
            # --min-age "${MIN_AGE}"

      - name: 上传日志
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: 迁移日志-${{ matrix.shard }}
          path: logs/
          retention-days: 7
